[{"content":"Description IMDLIB is a handy resource designed to assist researchers, meteorologist, and weather enthusiasts in analyzing and understanding climate data for India. In the latest version of IMDLIB (0.1.17), we have added computation of few popular climate indices in the IMDLIB package. This blog will showcases the seamless utilization of these pivotal climate indices in a programmatic fashion for the Godavari River Basin, providing a practical and efficient approach to their implementation.\n Load libraries 1 2 3 4  %matplotlib inline import imdlib as imd import numpy as np import string   Get Data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # load data start_yr, end_yr = 2015, 2019 variable = \u0026#39;rain\u0026#39; rain = imd.open_data(variable, start_yr, end_yr,\u0026#39;yearwise\u0026#39;, \u0026#39;../data\u0026#39;) # Fill Missing Data rain.fill_na() # Clip data for the Godavari River Basin (using Shapefile) rain.clip(\u0026#39;../gis/god.shp\u0026#39;) variable = \u0026#39;tmax\u0026#39; tmax = imd.open_data(variable, start_yr, end_yr,\u0026#39;yearwise\u0026#39;, \u0026#39;../data\u0026#39;) # Fill Missing Data tmax.fill_na() # Clip data for the Godavari River Basin (using Shapefile) tmax.clip(\u0026#39;../gis/god.shp\u0026#39;) variable = \u0026#39;tmin\u0026#39; tmin = imd.open_data(variable, start_yr, end_yr,\u0026#39;yearwise\u0026#39;, \u0026#39;../data\u0026#39;) # Fill Missing Data tmin.fill_na() # Clip data for the Godavari River Basin (using Shapefile) tmin.clip(\u0026#39;../gis/god.shp\u0026#39;)   Computation of climate indicess Consecutive wet days 1 2  cwd = rain.copy() cwd.compute(\u0026#39;cwd\u0026#39;, \u0026#39;A\u0026#39;)   Rainy days 1 2  dr = rain.copy() dr.compute(\u0026#39;dr\u0026#39;, \u0026#39;A\u0026#39;)   Diurnal Temperature Range 1 2 3  dtr_tmax = tmax.copy() dtr_tmin = tmin.copy() dtr_tmax.compute(\u0026#39;dtr\u0026#39;, \u0026#39;A\u0026#39;, tmin=dtr_tmin)   Heavy precipitation days 1 2  d64 = rain.copy() d64.compute(\u0026#39;d64\u0026#39;, \u0026#39;A\u0026#39;)   Modified Mann-Kendall test statistic 1 2  mmk_hr = rain.copy() mmk_hr.compute(\u0026#39;mmk_hr\u0026#39;, \u0026#39;A\u0026#39;)   Coolest night 1 2  mnadt = tmin.copy() mnadt.compute(\u0026#39;mnadt\u0026#39;, \u0026#39;A\u0026#39;)   Hottest day 1 2  mxadt = tmax.copy() mxadt.compute(\u0026#39;mxadt\u0026#39;, \u0026#39;A\u0026#39;)   Precipitation concentration index 1 2  pci = rain.copy() pci.compute(\u0026#39;pci\u0026#39;, \u0026#39;A\u0026#39;)   Total precipitation in wet days 1 2  rtwd = rain.copy() rtwd.compute(\u0026#39;rtwd\u0026#39;, \u0026#39;A\u0026#39;)   Maximum 5-days rainfall 1 2  rx5d = rain.copy() rx5d.compute(\u0026#39;rx5d\u0026#39;, \u0026#39;A\u0026#39;)   Maximum daily rainfall 1 2  rxa = rain.copy() rxa.compute(\u0026#39;rxa\u0026#39;, \u0026#39;A\u0026#39;)   Simple daily intensity index 1 2  sdii = rain.copy() sdii.compute(\u0026#39;sdii\u0026#39;, \u0026#39;A\u0026#39;)   Spearman’s Rho statistics 1 2  spr = rain.copy() spr.compute(\u0026#39;spr\u0026#39;, \u0026#39;A\u0026#39;)   Sen’s slope estimate 1 2  sse = rain.copy() sse.compute(\u0026#39;sse\u0026#39;, \u0026#39;A\u0026#39;)   Magnitude of trend 1 2  sstr = rain.copy() sstr.compute(\u0026#39;sstr\u0026#39;, \u0026#39;A\u0026#39;)   Convert IMDLIB data into xarray data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  # IMD to Netcdf and prepare for plot cwd = cwd.get_xarray() cwd = cwd.isel(time=-1) cwd = cwd.cwd dr = dr.get_xarray() dr = dr.isel(time=-1) dr = dr.dr dtr_tmax = dtr_tmax.get_xarray() dtr_tmax = dtr_tmax.isel(time=-1) dtr_tmax = dtr_tmax.dtr d64 = d64.get_xarray() d64 = d64.isel(time=-1) d64 = d64.d64 mmk_hr = mmk_hr.get_xarray() mmk_hr = mmk_hr.isel(time=-1) mmk_hr = mmk_hr.mmk_hr mnadt = mnadt.get_xarray() mnadt = mnadt.isel(time=-1) mnadt = mnadt.mnadt mxadt = mxadt.get_xarray() mxadt = mxadt.isel(time=-1) mxadt = mxadt.mxadt pci = pci.get_xarray() pci = pci.isel(time=-1) pci = pci.pci rtwd = rtwd.get_xarray() rtwd = rtwd.isel(time=-1) rtwd = rtwd.rtwd rx5d = rx5d.get_xarray() rx5d = rx5d.isel(time=-1) rx5d = rx5d.rx5d rxa = rxa.get_xarray() rxa = rxa.isel(time=-1) rxa = rxa.rxa sdii = sdii.get_xarray() sdii = sdii.isel(time=-1) sdii = sdii.sdii spr = spr.get_xarray() spr = spr.isel(time=-1) spr = spr.spr sse = sse.get_xarray() sse = sse.isel(time=-1) sse = sse.sse sstr = sstr.get_xarray() sstr = sstr.isel(time=-1) sstr = sstr.sstr   Plotting Data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134  import cartopy.crs as ccrs import cartopy from cartopy.feature import ShapelyFeature from cartopy.io.shapereader import Reader from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter import cmaps import matplotlib.colors as colors import matplotlib.image as mpimg from matplotlib.ticker import MultipleLocator import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable import matplotlib as mpl class MidpointNormalize(colors.Normalize): def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False): self.midpoint = midpoint colors.Normalize.__init__(self, vmin, vmax, clip) def __call__(self, value, clip=None): # I\u0026#39;m ignoring masked values and all kinds of edge cases to make a # simple example... x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1] return np.ma.masked_array(np.interp(value, x, y), np.isnan(value)) proj = ccrs.PlateCarree() lon_formatter = LongitudeFormatter(zero_direction_label=True) # lon_formatter = LongitudeFormatter() lat_formatter = LatitudeFormatter() # Shapefile Read sp_nm = \u0026#39;../gis/god.shp\u0026#39; shape_feature = ShapelyFeature(Reader(sp_nm).geometries(), proj, edgecolor=\u0026#39;black\u0026#39;) # # Get bounding box # import geopandas as gpd # tmp = gpd.read_file(sp_nm) # print(tmp.total_bounds) # print lower left (lon, lat) and upper right (lon, lat) # # 73.47881334, 16.53814697, 83.15886298, 22.69166667 fig, ax = plt.subplots(5, 3, figsize=(8, 11), subplot_kw={\u0026#39;projection\u0026#39;:proj}) fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.25, hspace=-0.5) plt.rcParams[\u0026#39;axes.xmargin\u0026#39;] = 0 plt.rcParams[\u0026#39;font.size\u0026#39;] = 11 plt.rcParams[\u0026#34;font.family\u0026#34;] = \u0026#34;Times New Roman\u0026#34; plt.rcParams[\u0026#34;font.weight\u0026#34;] = \u0026#34;normal\u0026#34; fs = 10 plt_lab = string.ascii_lowercase[:15] plt_tit = [\u0026#39;cwd\u0026#39;, \u0026#39;dr\u0026#39;, \u0026#39;dtr\u0026#39;, \u0026#39;d64\u0026#39;, \u0026#39;mmk_hr\u0026#39;, \u0026#39;mnadt\u0026#39;, \u0026#39;mxadt\u0026#39;, \u0026#39;pci\u0026#39;, \u0026#39;rtwd\u0026#39;, \u0026#39;rx5d\u0026#39;, \u0026#39;rxa\u0026#39;, \u0026#39;sdii\u0026#39;, \u0026#39;spr\u0026#39;, \u0026#39;sse\u0026#39;, \u0026#39;sstr\u0026#39;] f1_1 = cwd.plot(ax=ax[0, 0], transform=proj, cmap = cmaps.WhiteGreen, cbar_kwargs={\u0026#39;ticks\u0026#39;: [5, 10, 15, 20, 25], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;Days\u0026#39;}) f1_2 = dr.plot(ax=ax[0, 1], transform=proj, cmap = cmaps.MPL_Blues, cbar_kwargs={\u0026#39;ticks\u0026#39;: [38, 68, 98, 128], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;Days\u0026#39;}) f1_3 = dtr_tmax.plot(ax=ax[0, 2], transform=proj, cmap = cmaps.MPL_Oranges, cbar_kwargs={\u0026#39;ticks\u0026#39;: [9.8, 11.1, 12.4, 13.7], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;$^o$C\u0026#39;}) f1_4 = d64.plot(ax=ax[1, 0], transform=proj, cmap = \u0026#39;Blues\u0026#39;, cbar_kwargs={\u0026#39;ticks\u0026#39;: [0, 6, 12, 18], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;Days\u0026#39;}) vmin_f1_4 = -2 vmax_f1_4 = 2 norm_f1_4 = colors.TwoSlopeNorm(vmin=vmin_f1_4, vcenter=0, vmax=vmax_f1_4) f1_5 = mmk_hr.plot(ax=ax[1, 1], transform=proj, cmap = cmaps.CBR_coldhot_r, vmin=vmin_f1_4, vmax=vmax_f1_4, norm=norm_f1_4, cbar_kwargs={\u0026#39;ticks\u0026#39;: [-2, -1, 0, 1, 2], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;Z\u0026#39;}) f1_6 = mnadt.plot(ax=ax[1, 2], transform=proj, cmap = cmaps.MPL_YlGnBu_r, cbar_kwargs={\u0026#39;ticks\u0026#39;: [4, 8, 12], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;$^o$C\u0026#39;}) f1_7 = mxadt.plot(ax=ax[2, 0], transform=proj, cmap = \u0026#39;Reds\u0026#39;, cbar_kwargs={\u0026#39;ticks\u0026#39;: [40, 42, 44, 46], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;$^o$C\u0026#39;}) f1_8 = pci.plot(ax=ax[2, 1], transform=proj, cmap = cmaps.spread_15lev, cbar_kwargs={\u0026#39;ticks\u0026#39;: [18, 22, 26, 30], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;\u0026#39;}) f1_9 = rtwd.plot(ax=ax[2, 2], transform=proj, cmap = \u0026#39;jet_r\u0026#39;, cbar_kwargs={\u0026#39;ticks\u0026#39;: [500, 1500, 2500, 3500], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;mm/y\u0026#39;}) f1_10 = rx5d.plot(ax=ax[3, 0],transform=proj, cmap = cmaps.spread_15lev, cbar_kwargs={\u0026#39;ticks\u0026#39;: [80, 320, 550, 780], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;mm/y\u0026#39;}) f1_11 = rxa.plot(ax=ax[3, 1],transform=proj, cmap = cmaps.spread_15lev, cbar_kwargs={\u0026#39;ticks\u0026#39;: [40, 120, 200, 280], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;mm\u0026#39;}) f1_12 = sdii.plot(ax=ax[3, 2],transform=proj, cmap = cmaps.ncview_default_r, cbar_kwargs={\u0026#39;ticks\u0026#39;: [11, 19, 27, 35], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;\u0026#39;}) f1_13 = spr.plot(ax=ax[4, 0], cbar_kwargs={\u0026#39;ticks\u0026#39;: [-3, -1, 1, 3], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;Zsr\u0026#39;}) f1_14 = sse.plot(ax=ax[4, 1], cbar_kwargs={\u0026#39;ticks\u0026#39;: [-400, 0, 400], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;\u0026#39;}) f1_15 = sstr.plot(ax=ax[4, 2], cbar_kwargs={\u0026#39;ticks\u0026#39;: [-100, -50, 0, 50, 100], \u0026#34;shrink\u0026#34;:0.34, \u0026#34;aspect\u0026#34;:10, \u0026#39;label\u0026#39;:\u0026#39;%\u0026#39;}) count=0 for t_ax in ax.reshape(-1): t_ax.text(0.05, 0.85, f\u0026#39;({plt_lab[count]})\u0026#39;, size=15, color=\u0026#39;black\u0026#39;, transform=t_ax.transAxes) t_ax.text(0.35, 1.02, f\u0026#39;{plt_tit[count]}\u0026#39;, size=18, color=\u0026#39;black\u0026#39;, transform=t_ax.transAxes) t_ax.set(facecolor = \u0026#34;#f6f7f6\u0026#34;) t_ax.add_feature(shape_feature, facecolor=\u0026#34;None\u0026#34;) t_ax.set_yticks([16.3, 18.5, 20.7, 22.9], crs=proj) t_ax.yaxis.set_major_formatter(lat_formatter) # t_ax.yaxis.set_minor_locator(MultipleLocator(0.1)) t_ax.set_xticks([73.1, 76.6, 80.1, 83.6], minor=False, crs=proj) t_ax.xaxis.set_major_formatter(lon_formatter) # t_ax.xaxis.set_minor_locator(MultipleLocator(0.1)) t_ax.gridlines(linewidth=1, color=\u0026#39;gray\u0026#39;, alpha=0.25, linestyle=\u0026#39;--\u0026#39;) t_ax.set_xlabel(\u0026#39;\u0026#39;) t_ax.set_ylabel(\u0026#39;\u0026#39;) t_ax.set_title(\u0026#34;\u0026#34;) if count in range(12): t_ax.set_xticklabels(\u0026#34;\u0026#34;) if count % 3!=0: t_ax.set_ylabel(\u0026#34;\u0026#34;) t_ax.set_yticklabels(\u0026#34;\u0026#34;) count+=1   Sample Image: Image with title, caption, alt, ...   --","description":"IMDLIB demo for calculation of climate indices.","id":0,"section":"posts","tags":["climate","tool","softwares","installation","IMDLIB"],"title":"Computing Climate Indices using IMDLIB","uri":"https://saswatanandi.github.io/posts/climate_indices_imdlib/"},{"content":"Description Do you work with climate data and find yourself struggling to efficiently manipulate and process your data? Climate Data Operators (CDO) is a powerful tool that can help you analyze and process large amounts of climate data in a fast and efficient way. In this tutorial, I will guide you through the process of installing CDO (and it\u0026rsquo;s essential dependencies) on Linux from sources.\n Target Audience This guide is specifically designed for Linux users who are looking to install the Climate Data Operators (CDO) on their systems. If you are a Windows user, this guide may not be applicable to you. This guide is ideal for High Performance Computing (HPC) users who do not have root privileges on their systems. It is also well-suited for those who are enthusiastic about programming and want to get the most out of their CDO tour.\n Is it suitable for a experienced Linux user? YES Is it suitable for a novice Linux user? YES How? Answered at the end.   List of tools that will be installed during the CDO installation    Name  Version      zlib 1.2.11   HDF5 1.12.1   curl 7.80.0   netcdf-c 4.8.1   netcdf-fortran 4.5.3   udunits 2.2.28   expat 2.4.1   libxml2 2.9.12   sqlite3 2022-3400100   proj 8.2.0   CDO 1.9.10    Downloading Sources 1 2 3 4 5 6 7 8 9 10 11  wget https://www.zlib.net/fossils/zlib-1.2.11.tar.gz wget https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.12/hdf5-1.12.1/src/hdf5-1.12.1.tar.gz wget https://curl.se/download/curl-7.80.0.tar.gz wget https://github.com/Unidata/netcdf-c/archive/refs/tags/v4.8.1.tar.gz wget https://github.com/Unidata/netcdf-fortran/archive/refs/tags/v4.5.3.tar.gz wget https://downloads.unidata.ucar.edu/udunits/2.2.28/udunits-2.2.28.tar.gz wget https://github.com/libexpat/libexpat/releases/download/R_2_4_1/expat-2.4.1.tar.gz wget ftp://xmlsoft.org/libxml2/libxml2-2.9.12.tar.gz wget https://www.sqlite.org/2022/sqlite-tools-linux-x86-3400100.zip wget https://download.osgeo.org/proj/proj-8.2.0.tar.gz wget https://code.mpimet.mpg.de/attachments/download/24638/cdo-1.9.10.tar.gz   Extract Packages 1 2  find . -type f -name \u0026#39;*.tar.gz\u0026#39; -exec tar -xzvf {} \\; unzip sqlite-tools-linux-x86-3400100.zip   Compile Packages Assuming, we want to install cdo and all its dependencies in a directory defined by a variable prefix .\nGo to the respective package folder and perform the following task\nFor compiling proj we need to keep the extracted files from sqlite-tools-linux-x86-3400100.zip into any PATH locations of the system\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  # zlib ./configure --prefix=${prefix} make \u0026amp;\u0026amp; make install # HDF5 ./configure --prefix=${prefix} --with-zlib=${prefix} --enable-hl make \u0026amp;\u0026amp; make install # curl ./configure --prefix=${prefix} --with-zlib=${prefix} --with-gnutls make \u0026amp;\u0026amp; make install # netcdf-c ./configure --prefix=${prefix} --with-zlib=${prefix} --with-hdf5=${prefix} --enable-netcdf-4 LDFLAGS=\u0026#34;-L${prefix}/lib\u0026#34; CPPFLAGS=\u0026#34;-I${prefix}/include\u0026#34; make \u0026amp;\u0026amp; make install # netcdf-fortran ./configure --prefix=${prefix} --with-zlib=${prefix} --with-hdf5=${prefix} --with-netcdf=${w_d} LDFLAGS=\u0026#34;-L${prefix}/lib\u0026#34; CPPFLAGS=\u0026#34;-I${prefix}/include\u0026#34; make \u0026amp;\u0026amp; make install # udunits ./configure --prefix=${prefix} make \u0026amp;\u0026amp; make install # expat ./configure --prefix=${prefix} make \u0026amp;\u0026amp; make install # xml2 ./configure --prefix=${prefix} --with-expat=${prefix} --without-python LDFLAGS=\u0026#34;-L${prefix}/lib\u0026#34; CPPFLAGS=\u0026#34;-I${prefix}/include\u0026#34; make \u0026amp;\u0026amp; make install # proj ./configure --prefix=${w_d} LDFLAGS=\u0026#34;-L${prefix}/lib\u0026#34; CPPFLAGS=\u0026#34;-I${prefix}/include\u0026#34; make \u0026amp;\u0026amp; make install # cdo ./configure --prefix=${prefix} --with-netcdf=${prefix} --with-hdf5=${prefix} --with-netcdf4 --with-zlib=${prefix} --with-curl=${prefix} --with-udunits2=${prefix} --with-xml2=${prefix} --with-proj=${prefix} LDFLAGS=\u0026#34;-L${w_d}/lib\u0026#34; CPPFLAGS=\u0026#34;-I${prefix}/include\u0026#34; make \u0026amp;\u0026amp; make install   The above code can be be further tuned to alter your cdo installation experience.\nBonus I have created a bash installation script for CDO that automates the entire installation process and even allows you to take advantage of multiple cores for faster compilation.\nThe typical form of cdo installation now looks like this (isn\u0026rsquo;t this exciting?):\ncurl -s url | bash -s arg1 arg2 arg3 aarg4  Arguments When we suppy 4 arguments, their meaning are as follows:\nArg 1: \u0026quot;y\u0026quot; or \u0026quot;n\u0026quot;. Do you want to create a new directory? Arg 2: \u0026quot;y\u0026quot; or \u0026quot;n\u0026quot;. Do you want parallel make configuration? Arg 3: Full path name of the new folder to be created Arg 4: Integer number of CPU cores to use for building packages  If Arg 1 and Arg 2 both are \u0026lsquo;n\u0026rsquo;, we need only 2 args. In this case cdo will be installed in current working directory with no parallel make.\nIf Arg 1 = \u0026lsquo;y\u0026rsquo; and If Arg 2 = \u0026lsquo;n\u0026rsquo;; 3 rd argument is needed, which is full path name of the new folder to be created.\nIf Arg 1 = \u0026lsquo;n\u0026rsquo; and If Arg 2 = \u0026lsquo;y\u0026rsquo;; 3 rd argument is needed, which is number of CPU cores to use for building.\nExample An real example using the automated cdo installation script will look something like this;\n1  curl -s https://gist.githubusercontent.com/iamsaswata/4d1c2bd1711ecb42fede3bedb96f12cc/raw/bb41d9d221751d85fcf731613e1a9e8778e3e372/cdo_install.sh | bash -s y y /tmp/cdo 16   Benefits The CDO installation script offers several benefits over a manual installation:\n Automation: The script automates the entire installation process, saving you time and effort. Customization: The script allows you to customize your installation based on your needs, such as creating a new directory or using parallel make configuration. Speed: The script takes advantage of multiple CPU cores for faster compilation, which can significantly speed up the installation process.  ","description":"Tutorial showcasing Climate Data Operators (CDO) installation.","id":1,"section":"posts","tags":["climate","tool","softwares","installation","cdo"],"title":"Installing Climate Data Operators (CDO) on Linux from source","uri":"https://saswatanandi.github.io/posts/cdo_install/"},{"content":"Description Tutorial showcasing IMDLIB for real-time data processing.\nInstallation IMDLIB can be installed via pip, conda, or using the source file from Github. It is tested for both Windows and Linux platforms with 64 bit architecture only.\nInstallation using pip.\n1  pip install imdlib   Installation using conda.\n1  conda install -c iamsaswata imdlib   Installation from source file.\n1  pip install git+https://github.com/iamsaswata/imdlib.git   Usage Downloading real-time data from IMD  IMDLIB, with its v.0.1.15, now support processing of real-time daily IMD rainfall 0.25o and temperature data 0.50o.\n The steps are similar to the data downloading and opening of IMD gridded archive data.  An example is presented below. 1 2 3 4 5 6 7 8 9  import imdlib as imd # Downloading dail real-time rainfall data for India import imdlib as imd start_dy = \u0026#39;2020-01-31\u0026#39; end_dy = \u0026#39;2020-03-05\u0026#39; var_type = \u0026#39;rain\u0026#39; file_dir=\u0026#39;../data\u0026#39; data = imd.get_real_data(var_type, start_dy, end_dy, file_dir)   The output is:\nDownloading: rain for date 2020-01-31 Downloading: rain for date 2020-02-01 Downloading: rain for date 2020-02-02 Downloading: rain for date 2020-02-03 Downloading: rain for date 2020-02-04 Downloading: rain for date 2020-02-05 Downloading: rain for date 2020-02-06 Downloading: rain for date 2020-02-07 Downloading: rain for date 2020-02-08 Downloading: rain for date 2020-02-09 Downloading: rain for date 2020-02-10 Downloading: rain for date 2020-02-11 Downloading: rain for date 2020-02-12 Downloading: rain for date 2020-02-13 Downloading: rain for date 2020-02-14 Downloading: rain for date 2020-02-15 Downloading: rain for date 2020-02-16 Downloading: rain for date 2020-02-17 Downloading: rain for date 2020-02-18 Downloading: rain for date 2020-02-19 Downloading: rain for date 2020-02-20 Downloading: rain for date 2020-02-21 Downloading: rain for date 2020-02-22 Downloading: rain for date 2020-02-23 Downloading: rain for date 2020-02-24 Downloading: rain for date 2020-02-25 Downloading: rain for date 2020-02-26 Downloading: rain for date 2020-02-27 Downloading: rain for date 2020-02-28 Downloading: rain for date 2020-02-29 Downloading: rain for date 2020-03-01 Downloading: rain for date 2020-03-02 Downloading: rain for date 2020-03-03 Downloading: rain for date 2020-03-04 Downloading: rain for date 2020-03-05 Download Successful !!! Reading downloaded real-time dataset 1 2 3 4 5 6  import imdlib as imd start_dy = \u0026#39;2020-01-31\u0026#39; end_dy = \u0026#39;2020-03-05\u0026#39; var_type = \u0026#39;rain\u0026#39; file_dir=\u0026#39;../data\u0026#39; data = imd.open_real_data(var_type, start_dy, end_dy, file_dir)   ","description":"Tutorial showcasing IMDLIB for real-time data processing.","id":2,"section":"posts","tags":["hydrology","IMD","Softwares","github","pypi","conda"],"title":"Real time data processing using IMDLIB","uri":"https://saswatanandi.github.io/posts/imdlib_update_real/"},{"content":"Climate change is arguably the most alarming global concern of the twenty-first century, particularly due to the increased frequency of meteorological extremes, e.g., heatwaves, droughts, and floods. Heatwaves are considered a potential health risk and urge further study, robust preparedness, and policy framing. This study presents an analysis of heatwave characteristics for historical (1980–2014), near-future (2021–2055), and far-future (2056–2090) scenarios over three highly populated cities of South India, i.e., Bangalore, Chennai, and Hyderabad. Two different approaches, i.e., the India Meteorological Department (IMD) criterion and the percentile-based criterion, are considered for defining the threshold of a heatwave day. Nine general circulation models (GCMs) from the Coupled Model Inter-comparison Project phase 6 (CMIP6) experiment are selected, evaluated after bias correction, and the best performer was utilized to obtain the temperature projections corresponding to two shared socioeconomic pathways (SSP 2–4.5 and 5–8.5) for the future periods. The results reveal a high frequency of heatwave days over the cities in recent years from both approaches, which may further exacerbate in the future, thereby putting a large population at risk. The number of heatwave days is much higher for SSP5-8.5 than that for SSP2-4.5, depicting the direct effects of anthropogenic activities on the frequency of heatwaves. The detailed analysis of heatwave projections will help develop equitable heat resilient mitigation and adaptation strategies for the future, thereby alleviating their pernicious impacts. ","description":"","id":3,"section":"publication","tags":null,"title":"Heatwave analysis over south Indian cities","uri":"https://saswatanandi.github.io/publication/article/espr_2022/"},{"content":"In this study, the performance and hydrological utility of IMERG rainfall estimates over the Upper Bhima River basin, India, are comprehensively evaluated using a VIC-RAPID hydrologic model. Moreover, a bias-correction scheme based on the long short-term memory (LSTM) neural network method is proposed, and the results are compared with two commonly used bias-correction techniques. Results indicated that the spatial distribution of observed rainfall is well captured by IMERG; however, it showed a general tendency of overestimation, especially on a daily timescale. The LSTM-based approach showed notable improvements against the other bias-correction techniques substantiating its utility for accurately estimating rainfall amount and skillful detection of rainfall events in the study area. The VIC-RAPID model simulations for hydrological variables revealed a significant improvement in the performance of the bias-corrected IMERG product. In addition, the effect of the hydrological model recalibration with the different rainfall input datasets has also been elucidated. ","description":"","id":4,"section":"publication","tags":null,"title":"Hydrological utility of LSTM-corrected IMERG","uri":"https://saswatanandi.github.io/publication/article/gc_2022/"},{"content":"Controlling the damaging effects of fluvial flood events has been a major challenge for mankind. Integrated hydrologic-hydrodynamic models are often employed to estimate the flow and vital flood inundation information for mitigating such damages. The most important criterion for their implementation is that they should offer large-scale applicability with a finer resolution to have local relevance and practicability. This study presented an integrated modeling framework, VIC-RAPID-LISFP that couples a hydrological model (VIC), a river routing model (RAPID) and a hydrodynamic model (LISFLOOD-FP) for fast generation of high-resolution flow and flood inundation extent. The utility of the model is tested and demonstrated for a case study in the Upper Krishna River basin in India. The results showed that the simulated hourly streamflows from the calibrated model match reasonably well with the observations in terms of various efficiency measures. Also, the generated flood inundation maps from the model can reliably capture more than 80% of the satellite-derived flood inundation extent during both the low and high flow events. The proposed modeling framework is based on readily available open-source hydrographic data, and minimum meteorological information, so it has global applicability for supporting a flood management system with local relevance, especially for the data-scarce regions. ","description":"","id":5,"section":"publication","tags":null,"title":"Integrated flood modelling system","uri":"https://saswatanandi.github.io/publication/article/joh_2022/"},{"content":"Physically based distributed hydrological models are an invaluable tool for planning and management of water resource projects. However, a reliable prediction from hydrological models can only be expected if their unknown model parameters are estimated accurately. In place of laborious manual calibration of the parameters of the hydrological model, this study presents an automatic calibration scheme for the VIC-RAPID hydrological model using the self-adaptive differential evolution (SaDE) algorithm. The SaDE eliminates the laborious manual tuning of the two control parameters (mutation factor and crossover rate) of the conventional DE algorithm. The proposed approach is demonstrated with a case study in the upper Krishna river sub-basin for estimation of the 15 VIC-RAPID model parameters. The efficacy of the proposed calibration technique for hourly streamflow simulation is evaluated by using standard performance measures such as Nash-Sutcliffe Coefficient (NSE), Coefficient of Correlation (R2), and Percent Bias (PBIAS). Results from this study revealed the potential of SaDE for the parameter estimation of complex hydrological models. ","description":"","id":6,"section":"publication","tags":null,"title":"Efficient calibration of a macroscale hydrological model","uri":"https://saswatanandi.github.io/publication/book/picsnc_2021/"},{"content":"The physically based hydrological models require the estimation of various model parameters through calibration. Several past studies that focused on parameter estimation of hydrological models have found that no single objective performance criterion is adequate for matching different essential characteristics of the observation data. Since physically based hydrological models simulate many of the catchment hydrological processes, it needs to define multiple performance criteria to effectively use the information from various datasets and application of multiobjective optimization for attaining Pareto optimal solutions. In the present study, a Multiobjective Self-adaptive Differential Evolution algorithm (MOSaDE) is applied to perform multiobjective calibration of hydrological models. MOSaDE is an advancement of well-known Differential Evolution (DE) algorithm, using the notion of Pareto dominance, fast nondominated sorting approach, diversity preservation using crowding distance and elitist strategy of joining parent and offspring population. The parameter self-adaptation strategy in the MOSaDE also increases the robustness of the algorithm and alleviate the needs of computationally demanding sensitivity analysis of the algorithm parameters. The methodology is verified for calibration of Variable Infiltration Capacity (VIC) model, which is a popular physically based hydrological model, for a case study in Krishna basin, in India and the results are found to be promising. ","description":"","id":7,"section":"publication","tags":null,"title":"Multi-objective calibration of VIC-RAPID using MOSADE","uri":"https://saswatanandi.github.io/publication/book/cciwr_2021/"},{"content":"To overcome the drawbacks faced by the traditional manual calibration of hydrological models, this study employs an adaptive differential evolution (DE) algorithm for automatic calibration of Variable Infiltration Capacity (VIC) hydrological model. In the DE algorithm, proper tuning of its control parameters is laborious and generally needs a great amount of time and resources. Therefore, a self-adaptive scheme is presented to enhance the efficacy of the basic DE. The proposed automatic parameter estimation scheme is applied for a case study and evaluated its performance using standard performance measures of coefficient of correlation (R2), Nash–Sutcliffe coefficient (NSE), percent bias (PBIAS), and index of agreement (IoA). The findings from the study revealed that the adaptive DE was successful to optimize the unknown parameters of the VIC model accurately, which signified that the automatic calibration scheme is a credible alternative to the manual approach. ","description":"","id":8,"section":"publication","tags":null,"title":"SaDE based automatic calibration of VIC-RAPID integrated model","uri":"https://saswatanandi.github.io/publication/book/wmwg_2021/"},{"content":"Recently, physically-based hydrological models have been gaining much popularity in various activities of water resources planning and management, such as assessment of basin water availability, floods, droughts, and reservoir operation. Every hydrological model contains some parameters that must be tuned to the catchment being studied to obtain reliable estimates from the model. This study evaluated the performance of different evolutionary algorithms, namely genetic algorithm (GA), shuffled complex evolution (SCE), differential evolution (DE), and self-adaptive differential evolution (SaDE) algorithm for the parameter calibration of a computationally intensive distributed hydrological model, variable infiltration capacity (VIC) model. The methodology applied and tested for a case study of the upper Tungabhadra River basin in India and the performance of the algorithms is evaluated in terms of reliability, variability, efficacy measures in a limited number of function evaluations, their ability for achieving global convergence, and also by their capability to produce a skilful simulation of streamflows. The results of the study indicated that SaDE facilitates an effective calibration of the VIC model with higher reliability and faster convergence to optimal solutions as compared to the other methods. Moreover, due to the simplicity of the SaDE, it provides easy implementation and flexibility for the automatic calibration of complex hydrological models. ","description":"","id":9,"section":"publication","tags":null,"title":"Automatic model calibration","uri":"https://saswatanandi.github.io/publication/article/h20_2020/"},{"content":"Quantification of water-budget components is an essential step in the planning andmanagement of water resources in any river basin. Recently several studies emphasizedthat climate change would inevitably affect terrestrial hydrology. This study appliesdistributed hydrological modeling using the Variable Infiltration Capacity (VIC) modelto simulate the water balance components in the Sina basin, a drought-prone region inIndia. We analyzed the long-term spatiotemporal dynamics of precipitation, evapotrans-piration, surface runoff, and baseflow components, and their alterations due to impendingclimate change. The study employed the Mann-Kendall test and Sen’s slope estimators toanalyze the spatiotemporal trends of the water balance components during the baseline(1980–2010) and for the near future (2019–2040) periods. For the baseline period,precipitation exhibited an increasing trend, particularly during the monsoon season. Onthe evaluation of the annual water balance components, it showed that the basin has a lowannual rainfall (~ 718 mm) and relatively a very high annual evapotranspiration (~ 572mm) during 1980–2010, which might be the main reason for frequent droughts in thestudy basin. Further, for analyzing the climate change impacts on the water budget in theSina basin, the VIC model was forced with outputs from a set of global climate modelsfornearfuture(2019–2040) for two emission scenarios RCP4.5 and RCP8.5. Analysis ofthe results revealed that the water balance components in the near future would benegatively affected by climate change despite their increasing pattern in the baselineperiod. In comparison to the baseline (1980–2010), the surface runoff would decrease byas much as 32% for the near future, which stresses for planning and adaptation ofappropriate mitigation measures in the basin. ","description":"","id":10,"section":"publication","tags":null,"title":"Water budget and climate change","uri":"https://saswatanandi.github.io/publication/article/wrm_2020/"},{"content":"Description This is a python package to download and handle binary grided data from Indian Meterological department (IMD).\nInstallation IMDLIB can be installed via pip, conda, or using the source file from Github. It is tested for both Windows and Linux platforms with 64 bit architecture only.\nInstallation using pip.\n1  pip install imdlib   Installation using conda.\n1  conda install -c iamsaswata imdlib   Installation from source file.\n1  pip install git+https://github.com/iamsaswata/imdlib.git   IMDLIB is currently built with the following plugins. You need to have a python version \u0026gt;= 3.5 and install the below dependencies before installing IMDLIB from source.\n   Plugin Version No     certifi [2019.11.28]   matplotlib [3.1.3]   numpy [1.18.1]   pandas [0.25.3]   python-dateutil [ 2.8.1 ]   pytest [5.3.4]   pytz [ 2019.3]   requests [2.23.0]   scipy [1.4.1]   six [1.14.0]   xarray [0.14.1]   rioxarray (optional) [0.1.1]    Usage Downloading data from IMD IMDLIB is capable of downloading gridded rainfall and temperature data (min and max) from IMD Pune.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  import imdlib as imd # Downloading 8 years of rainfall data for India start_yr = 2010 end_yr = 2018 variable = \u0026#39;rain\u0026#39; # other options are (\u0026#39;tmin\u0026#39;/ \u0026#39;tmax\u0026#39;) file_dir = \u0026#39;dataFolder\u0026#39; \u0026#34;\u0026#34;\u0026#34; fn_format : str or None fn_format represent filename format. Default vales is None. Which means filesnames are accoding to the IMD naming convention If we specify fn_format = \u0026#39;yearwise\u0026#39;, filenames are renamed like \u0026lt;year.grd\u0026gt; file_dir : str or None Directory for downliading the files. If None, the currently working directory is used. sub_dir : bool True : if you need subdirectory for each variable type; False: Files will be saved directly under main directory proxies : dict Give details in curly bracket as shown in the example below e.g. proxies = { \u0026#39;http\u0026#39; : \u0026#39;http://uname:password@ip:port\u0026#39;} \u0026#34;\u0026#34;\u0026#34; data = imd.get_data(variable, start_yr, end_yr, fn_format=\u0026#39;yearwise\u0026#39;, file_dir=file_dir)   Reading downloaded binary dataset One major purposes of IMDLIB is to process gridded IMD meterological dataset. The original data is available in .grd file format. IMDLIB can read .grd file in xarray style and will create a IMD class objetct. For the already downloaded data, one should use the  imd.open_data() functionality for further analysis and processing.\n1 2 3 4 5 6 7 8 9  import imdlib as imd start_yr =2018 end_yr = 2018 variable = \u0026#39;rain\u0026#39; # other options are (\u0026#39;tmin\u0026#39;/ \u0026#39;tmax\u0026#39;) file_format = \u0026#39;yearwise\u0026#39; # other option (None), which will assume deafult imd naming convention file_dir = \u0026#39;/home/data/imd\u0026#39; # other option keep it blank data = imd.open_data(variable, start_yr, end_yr,\u0026#39;yearwise\u0026#39;, file_dir) data   \u0026lt;imdlib.core.IMD at 0x7f39b0960750\u0026gt;   file_dir should refer to top-lev directory. It should contain 3 sub-directories. rain, tmin, and tmax.\n  if file_dir exist, but no subdirectory, it will try to find the files in file_dir. But be careful if you are using file_format = 'yearwise', as it will not differentiate between 2018.grd for rainfall and 2018.grd for tmin.\n  if file_dir is not given, it will look for the associate subdirectories and files from the current directory.\n Get shape of IMD objecct 1  data.shape   (365, 135 129)  Get numpy. ndarray 1  np_array = data.data   Get xarray object 1 2  ds = data.get_xarray() type(ds)   xarray.core.dataarray.DataArray  Display mean rainfall in Map 1 2  ds = ds.where(ds[\u0026#39;rain\u0026#39;] != -999.) #Remove NaN values ds[\u0026#39;rain\u0026#39;].mean(\u0026#39;time\u0026#39;).plot()   Processing and Saving 1 2 3 4 5 6 7 8 9 10 11 12 13  # Get data for a given coordinare and convert to csv file lat = 20.03 lon = 77.23 out_dir=\u0026#39;/home/downloads/data\u0026#39; data.to_csv(file_name, lat, lon, out_dir) # Convert to netcdf file data.to_netcdf(file_name, out_dir) # Convert to GeoTIFF format data.to_geotiff(file_name, out_dir)   For converting to GeoTIFF, we are using [`rioxarray`](https://corteva.github.io/rioxarray/stable/) package, but it has not been considered as a dependency for IMDLIB. So, if a call is made to `to_geotiff()` functionaality, IMDLIB will check if *rioxarray* module is available to the system python path and if *rioxarray* is found, the corresponding GeoTIFF file will be generated or else a error will be thrown saying *rioxarray* is not installed.  NetCDF File Convention The IMDLIB focuses on producing netCDF (network Common Data Form) based final output as netCDF is the format most commonly used for climate model generated data. The netCDF Climate and Forecast (CF) Metadata Conventions, Version 1.7, has been adopted by IMDLIB for its efficient and consistent use with other standard netCDF based tool/applications. The epsg:4326 coordinate reference systems (CRS) is considered in CF naming convention and is vital for the function to_geotiff to work correctly. For more information on the CF convention, users are requested to visit CF Conventions Home Page  and XArray \u0026 CF integration  resources. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  test@test:~/data$ ncdump -h test.nc netcdf test { dimensions: time = 365 ; lat = 31 ; lon = 31 ; variables: double tmax(time, lat, lon) ; tmax:_FillValue = NaN ; tmax:units = \u0026#34;C\u0026#34; ; tmax:long_name = \u0026#34;Maximum Temperature\u0026#34; ; double lat(lat) ; lat:_FillValue = NaN ; lat:axis = \u0026#34;Y\u0026#34; ; lat:standard_name = \u0026#34;latitude\u0026#34; ; lat:long_name = \u0026#34;latitude\u0026#34; ; lat:units = \u0026#34;degrees_north\u0026#34; ; double lon(lon) ; lon:_FillValue = NaN ; lon:axis = \u0026#34;X\u0026#34; ; lon:long_name = \u0026#34;longitude\u0026#34; ; lon:units = \u0026#34;degrees_east\u0026#34; ; int64 time(time) ; time:standard_name = \u0026#34;time\u0026#34; ; time:long_name = \u0026#34;time\u0026#34; ; time:units = \u0026#34;days since 2010-01-01\u0026#34; ; time:calendar = \u0026#34;proleptic_gregorian\u0026#34; ; // global attributes: :Conventions = \u0026#34;CF-1.7\u0026#34; ; :title = \u0026#34;IMD gridded data\u0026#34; ; :source = \u0026#34;https://imdpune.gov.in/\u0026#34; ; :history = \u0026#34;2020-12-29 22:16:07.359709 Python\u0026#34; ; :references = \u0026#34;\u0026#34; ; :comment = \u0026#34;\u0026#34; ; :crs = \u0026#34;epsg:4326\u0026#34; ; }   License IMDLIB is available under MIT the open source license.\n","description":"A python package for handling IMD data.","id":11,"section":"softwares","tags":["hydrology","IMD","Softwares","github","pypi","conda"],"title":"IMDLIB","uri":"https://saswatanandi.github.io/softwares/imdlib/"},{"content":" This is the personal webpage of Saswata Nandi.\nI am a postdoctoral researcher at the Sierra Nevada Research Institute (SNRI), which was established in 2007 as ORU at UC Merced. Prior to this, I have completed my doctoral work from Indian Institute of Technology Bombay with Water Resources Engineering specialization.\nMy area of work includes: hydrological and land surface modelling, climate change, ensemble flow forecast, flood early warning system, remote sensing, drought risk assessment, water resources management and evolutionary optimization.  ","description":"Hugo, the world’s fastest framework for building websites","id":12,"section":"","tags":null,"title":"About","uri":"https://saswatanandi.github.io/about/"},{"content":"The assessment of climate change, especially in terms of rainfall variability, is of giant concern all over the world at present. Contemplating the high spatiotemporal variation in rainfall distribution, the prior estimation of precipitation is necessary at finer scales too. This study aims to develop an ARIMA model for prediction of monthly rainfall over Khordha district, Odisha, India. Due to the unavailability of recent rainfall data, monthly rainfall records were collected for 1901–2002. The rainfall during 1901–82 was used to train the model and that of 1983–2002 was used for testing and validation purposes. The model selection was made using Akaike information criterion (AIC) and Bayesian information criterion (BIC), and ARIMA (1, 2, 1) (1, 0, 1)12 was found to be the best fit model. The efficiency was evaluated by Nash–Sutcliffe efficiency (NSE) and coefficient of determination (R2). The model forecasts produced an excellent match with observed monthly rainfall data. The outstanding accuracy of the model for predicting monthly rainfall for such a long duration of 20 years justifies its future application over the study region, thereby aiding to a better planning and management. ","description":"","id":13,"section":"publication","tags":null,"title":"ARIMA-based forecasting of monthly precipitation","uri":"https://saswatanandi.github.io/publication/book/rfict_2018/"},{"content":"Drought is a natural hazard with severe socio-economic consequences. For agro-based country like India, this may further deteriorate the circumstances, thereby urging for precise quantification. This paper is about the application of meteorological drought indices namely Standardized Precipitation Index (SPI), Effective Drought Index (EDI) and Percent Normal Precipitation Index (PNPI) over Marathwada division, Maharashtra, India. The 3-hourly (0.25° × 0.25°) gridded rainfall data is collected from Multi-Source Weighted-Ensemble Precipitation (MSWEP) product for 1979-2014 and is converted to monthly temporal scale. All the three indices give similar results in meteorological drought characterization i.e., most parts of the Marathwada division are affected by frequent moderate or severe droughts while some parts have witnessed extreme drought conditions. However, EDI reveals a majority of the study area affected by extreme droughts, although with low frequency. This study will be helpful to policy makers for effective decision making regarding drought management. ","description":"","id":14,"section":"publication","tags":null,"title":"Meteorological drought characterization using multiple drought indices","uri":"https://saswatanandi.github.io/publication/misc/igarss_2017/"},{"content":"Floods can have catastrophic consequences and can have effects on the economy, environment and people. It initiates comprehensive assessment and forecasting of possible flooding events, which is typically carried out using hydrological models. Thus, the main objective of this study was to present a distributed hydrological model, namely Variable Infiltration Capacity (VIC) model for simulating the hydrological variables over Krishna River Basin, India and evaluating its performance by comparing with observed datasets. The main advantages of the VIC model compared to other physically based hydrological models, are the variable infiltration curve, which implementsa nonlinear function of the fractional grid cell area to scale the maximum infiltration for enabling runoff calculations for sub grid-scale areas and the parameterization of baseflow using a nonlinear recession curve. Meteorological forcingsat 0.5 degree by 0.5 degree spatial resolution from 1980 to 2005 over the basin were used to run the model at a daily time step. The model showed an acceptable performance during calibration and validation with Nash-Sutcliffe efficiency (NSE)=0.34 and coefficient of determination (R²)=0.60 for calibration and NSE=0.42 and R²=0.68 for validation periods. The results from VIC model shows that it canhandle large-scale variability. However,it has a tendency to overestimate the streamflow in the downstream portion possibly due to not considering the effect of storage structures in the present model.  ","description":"","id":15,"section":"publication","tags":null,"title":"Hydrological modelling over Krishna basin ","uri":"https://saswatanandi.github.io/publication/article/ewra_2017/"},{"content":"Estimation of precipitation is necessary for optimum utilization of water resources and their appropriate management. The economy of India being heavily dependent on agriculture becomes vulnerable due to lack of adequate irrigation facilities. In this paper, a multiple linear regression model has been developed to reckon annual precipitation over Cuttack district, Odisha, India. The model forecasts precipitation for a year considering annual precipitation data of its three preceding years. The model testing was performed over a century-long dataset of annual precipitation i.e. for 1904-2002. Assuming the intercept or constant of the multiple linear regression model as zero, the equation developed thereby displayed a superb result. The model predictions showed an excellent association with the observed data i.e. the coefficient of determination (R 2 ) and adjusted R 2 value was obtained to be 0.974 and 0.963 respectively. This reconciliation justifies the application of the developed model over the study area to forecast rainfall, thereby aiding in proper planning and management. ","description":"","id":16,"section":"publication","tags":null,"title":"MLR-based forecasting of precipitation","uri":"https://saswatanandi.github.io/publication/misc/i2ct_2017/"}]